# 4 Analysis

```{r, echo = FALSE, message = FALSE}
source(here::here("scripts/setup.R"))
```

## 4.1 RQ1 - Based on past electric vehicle adoption trends in Switzerland, can we forecast future adoption rates and pinpoint times of significant increases or decreases correlated with major events or policy changes?

Here is the process we used to compute those 4 regressions.

The first step was to choose dependent variables such as sales or EV
registrations:

1 . Sales Data :

-   The main advantage of this regressing with this variable is that it
    directly reflects market demand and consumer purchasing behaviour.
    Nonetheless, it can be influenced by short-term factors such as
    promotions or subsidies, which might not indicate long-term adoption
    trends.

2.  Registration Data :

-   The benefits we can obtain from including this variable is that it
    represents actual additions to the vehicle population and can be
    more indicative of long-term trends in EV adoption. On the other
    hand, it might lag behind sales data, as registration occurs
    post-purchase and can be influenced by administrative processes.

As we are interested in long-term trends in EV adoption and usage,
registration data is concluded to be our final choice. 

We then performed some analyse using linear regression and multivariate regression.

To evaluate the quality of our models we then reviewed the *results* and
checking weather the key *assumptions* of the regressions that are:

-   Linearity: if relationships between variables are linear
The linear assumption tells us if the relationship between the independent and dependent variables is a straight line. This makes the model simpler and easier to interpret.

We will diagnose this assumptions through a scatter plot of *observed vs. predicted values*, looking for a straight line pattern; if the points closely follow a straight line, it suggests a linear relationship.

-   Normal distribution: if the errors are normally distributed
In linear regression, the normal assumption refers to the idea that the errors or residuals, which represent the deviations between observed and predicted values, follow a normal (Gaussian) distribution.

We will diagnose this assumptions through an *histogram of residuals* which will allows us to see if the distribution of residuals resembles a normal distribution.

-   Homoscedasticity: if the errors have constant variance
A key indicator of homoscedasticity is a random spread of residuals across all levels of fitted values. If the residuals display a pattern, it suggests heteroscedasticity, which means the variance of residuals changes across fitted values, violating the assumption of homoscedasticity.

We will diagnose this assumptions through a scatter plot of *residuals vs. fitted values*, looking for an even spread (constant variance) of the residuals across different levels of the fitted values.

-   Multicollinearity : if independent variables are highly correlated with one and another (only for multivariable regression)

The VIF (Variance Inflation Factor) values will indicate the level of multicollinearity. When variables in a model are too similar to each other, it can ruin the accuracy of our predictions. 

We will diagnose this through the `VIF`  measure.  A rule of thumb is that if VIF is greater than 5 or 10, it indicates high multicollinearity. A high VIF indicates that a predictor variable is highly correlated with other predictors in the model, potentially causing instability in coefficient estimates.

If one of those assumptions doesn't hold, the model might not accurately capture the relationship, leading to incorrect predictions and conclusions.

Finally, we concluded by indicating the relevance of the results taking into account the quality of the model.

### 4.1.1. Simple Linear Regression

We started with the simple linear regression models to understand how well a single independent variable can predict EV adoption rates.

#### 4.1.1.1 With Oil

We started with oil price as a independent variable.

Linear models were fitted using the `lm()` function

Note: the decision to remove rows with missing values was justified as
the number of missing values in the Price column was relatively small
(28 out of a larger dataset) and couldn't be reliably imputed, ensuring
that the analysis was performed on a more complete and consistent
dataset.

```{r}
# Select the columns you want to keep in df_v_electric
df_v_electric <- df_v_electric %>%
  select(Location, Count, Date)

# Merge df_oil_monthly with df_v_electric based on the common 'Date' column
df_merged <- merge(df_v_electric, df_oil_monthly, by = "Date", all.x = TRUE)

# Remove rows with missing values in the 'Price' column
df_merged <- df_merged[complete.cases(df_merged), ]

# Splitting the data into training and testing sets
set.seed(123) # for reproducibility
split_index <- sample(1:nrow(df_merged), 0.8 * nrow(df_merged))
train_data <- df_merged[split_index, ]
test_data <- df_merged[-split_index, ]

# Fitting the linear model
mod1_lin <- lm(Count ~ Price, data = train_data)

# Summary of the model to view coefficients and statistics
summary(mod1_lin)

# Predicting with the test data
predictions <- predict(mod1_lin, test_data)
# Calculating residuals (difference between actual and predicted values)
residuals <- test_data$Count - predictions

# Calculating RMSE
rmse <- sqrt(mean(residuals^2))
print(paste("RMSE:", rmse))
# Creating a summary table for the linear model
table_regression <- tbl_regression(mod1_lin)
```

##### 4.1.1.1.1 Model Diagnostic
###### 4.1.1.1.1.2 Results

```{r}
table_regression
```

The linear regression analysis results indicate that the Price variable
has a very weak or negligible effect on explaining the variation in the
Count variable. Specifically:

-   The *coefficient* for Price is very close to zero (-0.00542),
    indicating that there is almost no linear relationship between Price
    and Count.
-   The *p-value* for Price (0.97) is much greater than the common
    significance level of 0.05. This high p-value suggests that Price is
    not statistically significant in predicting Count, as it fails to
    reject the null hypothesis that the coefficient is zero.
-   The *R-*squared value is very low (3.83e-07), which indicates that
    the linear regression model solely explains a negligible fraction of
    the variance related to the variable Count.\
-   The *Root Mean Squared Erro*r (RMSE) is relatively high (247),
    suggesting that the model's predictions have a substantial amount of
    error.

###### 4.1.1.1.1.1.2 Linearity

```{r}
plot_data <- data.frame(
  Observed = test_data$Count,
  Predicted = predictions
)

# Create ggplot object for observed vs predicted values
p <- ggplot(plot_data, aes(x = Predicted, y = Observed)) +
  geom_point(aes(color = Observed), alpha = 0.6) +  # Use color to represent the Observed values
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +  # Line y=x for reference
  scale_color_viridis(option = "C", direction = 1) +  # Consistent color scheme with the previous plots
  theme_minimal() +
  theme(text = element_text(size = 14), legend.position = "bottom") +  # Consistent theme and text size
  labs(title = "Observed vs. Predicted", x = "Predicted Values", y = "Observed Values", color = "Observed Count") +
  expand_limits(x = 0, y = 0)  # Ensure that the plot starts at 0

# Convert to a plotly interactive plot for consistency with the previous plots
ggplotly(p, tooltip = "text", width = 600, height = 400)
```

The graph indicates a potential issue with the linearity assumption, as
the observed values for low predicted values are more spread out and not
evenly distributed along a straight line, suggesting the model may not
be an appropriate fit for the data.

###### 4.1.1.1.1.1.3 Homoscedasticity

```{r}
# Create a data frame for plotting
plot_data <- data.frame(
  Fitted = predictions,
  Residuals = residuals
)

# Create ggplot object
p <- ggplot(plot_data, aes(x = Fitted, y = Residuals)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(aes(color = Residuals), alpha = 0.6) +
  scale_color_viridis(option = "C", direction = 1) +
  theme_minimal() +
  theme(text = element_text(size = 14), legend.position = "bottom") +
  labs(title = "Residuals vs. Fitted", x = "Fitted Values", y = "Residuals", color = "Residual Size")+
  expand_limits(y = -1000)  # Extend y-axis

# Convert to a plotly interactive plot
ggplotly(p, width = 600, height = 400)
```

This plot shows a pattern where the majority of residuals are clustered
around a narrow range of fitted values, with a few extreme residuals.
This could indicate that the model is not capturing the variability in
the data. We also observe the presence of extreme outliers or
influential points that are affecting the model fit.

Note : The outliers represent rare but possible scenarios within the dataset,
providing valuable insights into the extremes of the observed
phenomenon, and should therefore be retained for a comprehensive
analysis of the data's behavior.

###### 4.1.1.1.1.1.4 Normality

```{r}
# Histogram of Residuals
p <- ggplot(plot_data, aes(x = Residuals, fill = ..count..)) +
  geom_histogram(binwidth = 250, alpha = 0.6) +  # Wider bins for clearer view
  scale_fill_viridis_c(option = "C", begin = 0.3, end = 0.7, direction = -1) +  # Single color scale
  theme_minimal() +
  theme(text = element_text(size = 14)) +  # Larger text for better readability
  labs(title = "Histogram of Residuals", x = "Residuals", y = "Frequency", fill = "Frequency")
ggplotly(p, width = 600, height = 400 )
```

This plot shows that the residuals are not normally distributed.
Instead, there is a large spike near zero and a few large residuals,
confirming that there are outliers and that the model is not appropriate
for the data.

##### 4.1.1.1.3 Conclusion

In summary, based on these results and the diagnostic graphs, it appears
that the Price variable does not have a meaningful impact on predicting
the Count variable, and the linear regression model is *not suitable*
for explaining the relationship between these two variables. Further
exploration of the data and potentially considering other factors or
modeling approaches may be necessary to improve predictive accuracy.

The diagnostic plots obtained from our regression analysis indicate possible issues with linearity, normality, and homoscedasticity, highlighting the need to reconsider the model or explore alternative methods.

#### 4.1.1.2. With google trends

We then continue with the google trends, `SearchRatio`, as an independent variable.
```{r}
# Merge the two datasets based on the common Date column
df_merged <- merge(df_merged, df_gtrends, by = "Date")
# Check for missing values in df_merged
#sum(is.na(df_merged))
# Check for missing values in each column of df_merged
#colSums(is.na(df_merged))

# Splitting the data into training and testing sets
set.seed(123) # for reproducibility
split_index <- sample(1:nrow(df_merged), 0.8 * nrow(df_merged))
train_data <- df_merged[split_index, ]
test_data <- df_merged[-split_index, ]

# Fitting the linear model
mod2_lin <- lm(Count ~ SearchRatio, data = train_data)

# Summary of the model to view coefficients and statistics
summary(mod2_lin)

# Predicting with the test data
predictions <- predict(mod2_lin, test_data)

# Calculating residuals (difference between actual and predicted values)
residuals <- test_data$Count - predictions

# Calculating RMSE
rmse <- sqrt(mean(residuals^2))
print(paste("RMSE:", rmse))

# Creating a summary table for the linear model
table_regression2 <- tbl_regression(mod2_lin)
```

##### 4.1.2.1 Model Diagnostic
###### 4.1.1.2.1.1. Results

```{r}
# Viewing the table
table_regression2
```

The linear regression analysis results indicate that the SearchRatio
variable has a small but *significant* effect on explaining the
variation in the Count variable.

-   The coefficient for SearchRatio is 5.957, indicating that there is a
    positive linear relationship between SearchRatio and Count. For each
    unit increase in SearchRatio, the Count increases by an average of
    5.957 units.
-   The p-value for SearchRatio is less than 2e-16, which is far below
    the common significance level of 0.05. This extremely low p-value
    strongly suggests that SearchRatio is statistically significant in
    predicting Count, allowing us to reject the null hypothesis that the
    coefficient is zero.
-   The R-squared value is 0.0695, which indicates that the linear
    regression model explains about 6.95% of the variance in the Count
    variable. This is a modest amount, indicating that while SearchRatio
    does contribute to explaining Count, other factors are also likely
    to play a significant role.
-   The Root Mean Squared Error (RMSE) is 240.6, suggesting that the
    model's predictions have a moderate amount of error. This figure
    should be evaluated in the context of the magnitude of Count values
    to determine its practical significance.

###### 4.1.2.1.1.2 Linearity

```{r}
plot_data <- data.frame(
  Observed = test_data$Count,
  Predicted = predictions
)

# Create ggplot object for observed vs predicted values
p <- ggplot(plot_data, aes(x = Predicted, y = Observed)) +
  geom_point(aes(color = Observed), alpha = 0.6) +  # Use color to represent the Observed values
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +  # Line y=x for reference
  scale_color_viridis(option = "C", direction = 1) +  # Consistent color scheme with the previous plots
  theme_minimal() +
  theme(text = element_text(size = 14), legend.position = "bottom") +  # Consistent theme and text size
  labs(title = "Observed vs. Predicted", x = "Predicted Values", y = "Observed Values", color = "Observed Count") +
  expand_limits(x = 0, y = 0)  # Ensure that the plot starts at 0

# Convert to a plotly interactive plot for consistency with the previous plots
ggplotly(p, tooltip = "text", width = 600, height = 400)

```

This graph shows that for a wide range of predicted values, the observed
values are consistently low, suggesting that the model may not be
effectively capturing the variance in the observed data, and there could
be an issue with both the linearity and precision of the model's
predictions.

###### 4.1.2.1.1.3. Homoscedasticity

```{r}
# Create a data frame for plotting
plot_data <- data.frame(
  Fitted = predictions,
  Residuals = residuals
)

# Create ggplot object for Residuals vs. Fitted
p_residuals_fitted <- ggplot(plot_data, aes(x = Fitted, y = Residuals)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = 'red') +
  geom_point(aes(color = Residuals), alpha = 0.6) +
  scale_color_viridis(option = "C", direction = 1) +
  theme_minimal() +
  theme(text = element_text(size = 14), legend.position = "bottom") +
  labs(title = "Residuals vs. Fitted", x = "Fitted Values", y = "Residuals", color = "Residual Size") +
  expand_limits(y = -1000)  # Extend y-axis

# Convert to a plotly interactive plot
ggplotly(p_residuals_fitted, width = 600, height = 400)
```

The residual plots suggest that there may be non-linearity in the
relationship between SearchRatio and Count or the presence of
*outliers*, as indicated by the large residuals for higher fitted
values.

###### 4.1.2.1.1.4 Normality

```{r}
# Create ggplot object for Histogram of Residuals
p_histogram_residuals <- ggplot(plot_data, aes(x = Residuals, fill = ..count..)) +
  geom_histogram(binwidth = 250, alpha = 0.6) +  # Adjust binwidth as needed
  scale_fill_viridis_c(option = "C", begin = 0.3, end = 0.7, direction = -1) +
  theme_minimal() +
  theme(text = element_text(size = 14)) +
  labs(title = "Histogram of Residuals", x = "Residuals", y = "Frequency", fill = "Frequency")

# Convert to a plotly interactive plot
ggplotly(p_histogram_residuals, width = 600, height = 400)
```

As for the other linear regression, the histogram shows a right-skewed
distribution with a long tail, indicating and non-normal distribution
and the presence of outliers.

##### 4.1.1.2.2 Conclusion

Overall, while there is a statistically significant relationship between
SearchRatio and Count, the model's R-squared value suggests that other
factors not included in the model may also influence the Count variable.
One might want to explore additional variables along with more complex
models to improve predictive accuracy.

The diagnostic plots from our regression analysis further suggest
potential violations of linearity, normality, and homoscedasticity,
which may necessitate reevaluation of the model or the use of
alternative methods.

### 4.1.1.3 Multivariable Regression

Given the limitations of simple linear models in explaining our dependent variable, EV adoption, likely due to the intricate interplay of various contributing factors, we will now transition to a more comprehensive approach using a multiple linear regression model.

#### 4.1.1.1.3.1 With Demographic groups, Oil Price and Google Trend

We first explored the combined influence of Demographic groups, Oil Price and Google Trend as predictors.
```{r}
# Merge the data frames on the 'Year' column
df_merged <- merge(df_merged, df_demographic, by.x = "Date", by.y = "Year")

# Splitting the data into training and testing sets
set.seed(123) # for reproducibility
split_index <- sample(1:nrow(df_merged), 0.8 * nrow(df_merged))
train_data <- df_merged[split_index, ]
test_data <- df_merged[-split_index, ]

# Fitting the multivariable linear model
mod1_multi <- lm(Count ~ SearchRatio + Price + `Generation Z` + Millennials + `Generation X` + `Baby Boomers`, data = df_merged)

# Summary of the model to view coefficients and statistics
summary(mod1_multi)

# Predicting with the test data
predictions <- predict(mod1_multi, test_data)

# Evaluating the model
# Calculating R-squared value
r_squared <- cor(test_data$Count, predictions)^2
cat("R-squared: ", r_squared, "\n")

# Calculating RMSE (Root Mean Squared Error)
rmse <- sqrt(mean((predictions - test_data$Count)^2))
cat("RMSE: ", rmse, "\n")

# Create a summary table for the linear model
table_regression_mod1_multi <- tbl_regression(mod1_multi)

# Print the table
table_regression_mod1_multi
```

##### 4.1.1.3.1.1 Model Diagnostic

In multivariable regression, we are going to check the same key
assumptions of the model as for the linear regression. However, there's
an additional need to check for *multicollinearity* among predictors.

###### 4.1.1.3.1.2 Results

The multilinear regression analysis results indicate that most of the
independent variables have a weak or negligible effect on explaining the
variation in the Count variable.

-   The *coefficient* for `SearchRatio` is slightly above zero (1.04e+00),
    but with a *p-value* of 0.437, it suggests that SearchRatio is not
    statistically significant in predicting EV adoption.
-   The *coefficient* for `Price` is also very close to zero (4.10e-02), and
    its *p-value* of 0.885 reinforces the conclusion that `Price` does not
    significantly contribute to the model.
-   The generational variables (`Generation Z`, `Millennials`, `Generation X`)
    have very small *coefficients* (ranging from -1.02e-03 to 1.38e-03)
    and *p-values* well above the significance level, indicating that
    these, too, are not statistically significant predictors of EV adoption,
    with the exception of `Baby Boomers`.
-   `Baby Boomers` is the only variable that shows a statistically
    significant relationship with Count (*coefficient* = 6.32e-04, *p-value*
    = 0.018)
-   The *R-squared* value of the model is low (0.0924), meaning it only
    explains about 9.24% of the variance in the EV adoption variable, which is
    not substantially improved when considering the *adjusted R-squared*
    (0.0815).
-   The *Root Mean Squared Error* (RMSE) is 35.6, which suggests that the
    model's predictions have a moderate amount of error relative to the
    magnitude of EV adoption

###### 4.1.1.3.1.3 Linearity

```{r}
plot_data <- data.frame(
  Observed = test_data$Count,
  Predicted = predictions
)

# Create ggplot object for observed vs predicted values
p <- ggplot(plot_data, aes(x = Predicted, y = Observed)) +
  geom_point(aes(color = Observed), alpha = 0.6) +  # Use color to represent the Observed values
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +  # Line y=x for reference
  scale_color_viridis(option = "C", direction = 1) +  # Consistent color scheme with the previous plots
  theme_minimal() +
  theme(text = element_text(size = 14), legend.position = "bottom") +  # Consistent theme and text size
  labs(title = "Observed vs. Predicted", x = "Predicted Values", y = "Observed Values", color = "Observed Count") +
  expand_limits(x = 0, y = 0)  # Ensure that the plot starts at 0

# Convert to a plotly interactive plot for consistency with the previous plots
ggplotly(p, tooltip = "text", width = 600, height = 400)
```

The scatter plot shows many points along the lower left, suggesting the model may underpredict for higher actual values, as evidenced by points falling above the red dashed line, which represents perfect prediction. The color intensity indicates fewer occurrences of higher values.

###### 4.1.1.3.1.4 Homoscedasticity

```{r}
residuals <- test_data$Count - predictions

# Create a data frame for plotting
plot_data <- data.frame(
  Fitted = predictions,
  Residuals = residuals
)

# Create ggplot object for Residuals vs. Fitted
p_residuals_fitted <- ggplot(plot_data, aes(x = Fitted, y = Residuals)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = 'red') +
  geom_point(aes(color = Residuals), alpha = 0.6) +
  scale_color_viridis(option = "C", direction = -1) +
  theme_minimal() +
  labs(title = "Residuals vs. Fitted - Multivariable Model", x = "Fitted Values", y = "Residuals")

# Convert to a plotly interactive plot
ggplotly(p_residuals_fitted, width = 600, height = 400)
```

This plot indicates some non-random patterns in the residuals. The spread of residuals is not consistent across the range of fitted values, suggesting potential issues with homoscedasticity and possibly with the linearity assumption. The model may not be capturing all the systematic information present in the data.

###### 4.1.1.3.1.5 Normality

```{r}
plot_data <- data.frame(Residuals = residuals)

# Create ggplot object for Histogram of Residuals
p_histogram_residuals <- ggplot(plot_data, aes(x = Residuals, fill = ..count..)) +
  geom_histogram(binwidth = 20, alpha = 0.7) +  # Adjust binwidth as necessary
  scale_fill_viridis_c(option = "C", begin = 0.3, end = 0.7, direction = -1) +  # Single color scale
  theme_minimal() +
  labs(title = "Histogram of Residuals", x = "Residuals", y = "Frequency", fill = "Frequency")

# Print the plot
ggplotly( p_histogram_residuals, width = 600, height = 400)
```

This histogram indicates a distribution of residuals that is not symmetric and shows a peak at the center. This central peak is a good sign, as it often indicates that the model's predictions are on average correct, but the spread and potential skewness of the data still need to be assessed for normality.

###### 4.1.1.3.1.6 Multicollinearity

```{r}
vif_values <- vif(mod1_multi)

# Print VIF values
print(vif_values)

# Interpret VIF values
# A rule of thumb is that if VIF is greater than 5 or 10, it indicates high multicollinearity.
high_vif <- vif_values[vif_values > 5]
if(length(high_vif) > 0){
  print("The following variables have a high VIF indicating potential multicollinearity:")
  print(high_vif)
} else {
  print("No evidence of concerning multicollinearity among the predictor variables.")
}

vif_values <- c(SearchRatio = 7.10, Price = 1.76, `Generation Z` = 88.11, 
                Millennials = 48.53, `Generation X` = 289.98, `Baby Boomers` = 110.94)

# Create a data frame from the VIF values
vif_df <- data.frame(
  Variable = names(vif_values),
  VIF = unname(vif_values),
  Multicollinearity_Interpretation = c(
    "Moderate to high, indicating potential concerns.",
    "Low, suggesting little to no multicollinearity.",
    "Very high, indicating significant multicollinearity.",
    "High, indicating significant multicollinearity.",
    "Very high, indicating significant multicollinearity.",
    "Very high, indicating significant multicollinearity."
  )
)

# Generate the summary table
vif_table <- kable(vif_df, "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F) %>%
  column_spec(1, bold = TRUE, width = "15em") %>%
  column_spec(2, width = "5em") %>%
  column_spec(3, width = "30em")

# Print the table to view it in R Markdown or R HTML output
vif_table
```

Not surprinsingly, the VIF was high among the generational variables, which should be addressed to improve the model's interpretability and reliability.

SearchRatio also demonstrate a high VIF, even though it’s not as extreme as for the generational variables.

##### 4.1.1.3.2. Conclusion

```{r}
effects <- as.data.frame(fortify(mod1_multi))

# Create ggplot object for 'Baby Boomers' Effect
p_baby_boomers_effect <- ggplot(effects, aes_string(x = "`Baby Boomers`", y = ".fitted")) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, color = 'red', linetype = "dashed") +
  theme_minimal() +
  labs(title = "Baby Boomers Effect on EV Adoption", x = "Baby Boomers", y = "Fitted Values")

# Convert to a plotly interactive plot
ggplotly(p_baby_boomers_effect, width = 600, height = 400)

```

This multivariate linear regression model does not appear to have a
strong explanatory power, as indicated by the low adjusted R-squared
value and the relatively high RMSE. Additionally, only the
`Baby Boomers` variable shows statistical significance, as the graph demonstrate, in predicting the
Count, while other variables do not appear to be significant in this
context. However, given the high VIF this result should be interpreted
with caution. Refining the model or exploring other variables to improve
its predictive performance might be suggestible.

#### 4.1.1.3.2 Adding Political Parties

As the initial results were inconclusive, we opted to incorporate the Political Parties dataset and perform a backward integration to determine the most suitable model for our prediction.

```{r}
# Remove 'Confederation' from df_merged
df_multi_reg <- df_merged[df_merged$Location != 'Confederation', ]

# Step 2: Aggregate data for 'Switzerland' in politic data, For each year, sum the values of the 26 cantons to create a combined observation labeled "Switzerland". and then divide by 26
political_combined_data$Year <- year(ymd(political_combined_data$Year))
df_politics <- political_combined_data %>%
  group_by(Year) %>%
  summarise(across(c(`Against`, `Slightly Against`, `Neutral`, `Slightly in Favour`, `In Favour`), sum, na.rm = TRUE)) %>%
  mutate(Canton = 'Switzerland')

# Append the new 'Switzerland' rows to df_politics
df_politics <- bind_rows(political_combined_data, df_politics)

# List of column names you want to divide by 26
columns_to_divide <- c("Against", "Slightly Against", "Neutral", "Slightly in Favour", "In Favour")

df_politics <- df_politics %>%
  mutate_at(columns_to_divide, list(~./26))

# Step 3: Align 'Date' in df_multi_reg to 'Year' in df_politics 
df_multi_reg$Year <- year(ymd(df_multi_reg$Date))
df_multi_reg <- select(df_multi_reg, -Date)

#Merge the datasets on the aligned 'Location/Canton' and 'Date/Year' columns.
df_politics$Location <- df_politics$Canton 

# Step 4: Merge the datasets on 'Canton' and 'Year'
df_multi_reg <- merge(df_multi_reg, df_politics, by = c("Location", "Year"), all = FALSE)

# Reorder columns in a data frame
df_multi_reg <- df_multi_reg %>%
  select(Count, everything())

df_multi_reg <- df_multi_reg %>% select(-Canton, -KANTONSNUM)
any(is.na(df_multi_reg))

# Perform regression analysis without 'Location'
full_model <- lm(Count ~ Year + Price + SearchRatio + `Generation Z` + Millennials + `Generation X` + `Baby Boomers` + Against + `Slightly Against` + Neutral + `Slightly in Favour` + `In Favour`, data = df_multi_reg)

# Perform backward elimination
reduced_model <- step(full_model, direction = "backward")

# View the summary of the reduced model
summary(reduced_model)

# Perform backward elimination
reduced_model <- step(full_model, direction = "backward")

# View the summary of the reduced model
summary(reduced_model)
# Create a summary table for the linear model
table_regression_mod2_multi <- tbl_regression(reduced_model)

```

##### 4.1.1.3.2.1 Model Diagnosis

###### 4.1.1.3.2.1.1 Results
```{r}
# Print the table
table_regression_mod2_multi
```

1.  **Starting Model**: The initial model includes a wide range of
    predictor variables: `Year`, `Price`, `SearchRatio`, various generational
    groups (`Generation Z`, `Millennials`, `Generation X`,`Baby Boomers`), and
    several categories of opinions (`Against`, `Slightly Against`, `Neutral`,
    `Slightly in Favour`, `In Favour`).

2.  **Stepwise Process**: The stepwise procedure iteratively removes the
    least significant variables based on their contribution to the model
    (using the Akaike Information Criterion, *AIC*, as a guide). A lower
    AIC indicates a better model fit with respect to the number of
    variables.

3.  **Model Refinement**: As we progress through the steps, we observe
    the removal of several variables like `Baby Boomers`, `Millennials`,
    and `Generation X`. This suggests that these variables were not
    significantly contributing to the explanation of variations in
    `Count`.

4.  **Final Model**: The last step shows the model with the variables:
    `SearchRatio`, `Slightly Against`, `Neutral`, and `In Favour`. This model
    has an *AIC* of 710, which is lower than the starting *AIC* of 715,
    indicating a more efficient model.

5.  **Significance of Remaining Variables**: In the final model, all the
    variables are considered significant contributors. If any were to be
    removed, it would result in a higher AIC, indicating a less optimal
    model.

6.  **Interpretation of Variables**:

    -   `SearchRatio`, `Slightly Against`, `Neutral`, and `In Favour`
        are significant predictors for `Count`.
    -   The absence of demographic variables in the final model suggests
        that the adoption count may not be strongly related to these
        demographic factors, or their effect is captured by other
        variables.
    -   The presence of opinion-related variables (like `In Favour`)
        indicates a possible correlation between public opinion and the
        count of the dependent variable (possibly related to EV adoption
        or similar context).

7.  **Cautions**: While stepwise regression is useful for variable
    selection, it can sometimes lead to overfitting or neglecting
    important variables that don't show strong individual effects but
    are important in combination with others. Hence, the results should
    be interpreted with caution, and further analysis (like checking for
    multicollinearity, interactions between variables, etc.) is
    recommended to validate the findings.

###### 4.1.1.3.2.1.2 Linearity

```{r}
# Step 1: Create predictions
df_multi_reg$Predicted <- predict(reduced_model, newdata = df_multi_reg)

# Step 2: Combine predicted and observed values
plot_data <- data.frame(Observed = df_multi_reg$Count, Predicted = df_multi_reg$Predicted)

# Step 3: Plot using ggplot2
p <- ggplot(plot_data, aes(x = Predicted, y = Observed)) +
  geom_point(aes(color = Observed), alpha = 0.6) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  scale_color_viridis(option = "C", direction = 1) +
  theme_minimal() +
  theme(text = element_text(size = 14), legend.position = "bottom") +
  labs(title = "Observed vs. Predicted", x = "Predicted Values", y = "Observed Values", color = "Observed Count") +
  expand_limits(x = 0, y = 0)

# Step 4: Convert to a plotly interactive plot
ggplotly(p, tooltip = "text", width = 600, height = 400)

```

This graph shows that for lower predicted values, the observed and predicted values are closer, but as values increase, the predictions become less accurate. This suggest that the model's predictions are not consistent across the range of data, especially at higher values. This could indicate potential model limitations or the influence of outliers or leverage points at higher values.

###### 4.1.1.3.2.1.3 Homoscedasticity

```{r}

# Step 1: Calculate residuals and get fitted values
df_multi_reg$Residuals <- residuals(reduced_model)
df_multi_reg$Fitted <- fitted(reduced_model)

# Step 2: Prepare data for plotting
plot_data <- data.frame(Fitted = df_multi_reg$Fitted, Residuals = df_multi_reg$Residuals)

# Step 3: Create ggplot object for Residuals vs. Fitted
p_residuals_fitted <- ggplot(plot_data, aes(x = Fitted, y = Residuals)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = 'red') +
  geom_point(aes(color = Residuals), alpha = 0.6) +
  scale_color_viridis(option = "C", direction = -1) +
  theme_minimal() +
  labs(title = "Residuals vs. Fitted - Multivariable Model", x = "Fitted Values", y = "Residuals")

# Step 4: Convert to a plotly interactive plot
ggplotly(p_residuals_fitted, width = 600, height = 400)

```

This graph shows a pattern where residuals spread out as the fitted values increase. The presence of a few large residuals suggests potential outliers or influential points. This pattern suggests that the model may not be capturing all the complexities of the data.

###### 4.1.1.3.2.1.4 Normality

```{r}

# Step 1: Calculate residuals
residuals <- residuals(reduced_model)

# Step 2: Prepare data for plotting
plot_data <- data.frame(Residuals = residuals)

# Step 3: Create ggplot object for Histogram of Residuals
p_histogram_residuals <- ggplot(plot_data, aes(x = Residuals, fill = ..count..)) +
  geom_histogram(binwidth = 20, alpha = 0.7) +  # Adjust binwidth as necessary
  scale_fill_viridis_c(option = "C", begin = 0.3, end = 0.7, direction = -1) +  # Single color scale
  theme_minimal() +
  labs(title = "Histogram of Residuals", x = "Residuals", y = "Frequency", fill = "Frequency")

# Step 4: Convert to an interactive plot
ggplotly(p_histogram_residuals, width = 600, height = 400)

```

The histogram displays a distribution of residuals with a significant peak in the center, suggesting that many of the residuals are small and close to zero, which is a good sign for model accuracy. However, there are also some residuals far from zero, indicating potential outliers or model misspecification. The presence of outliers can distort the overall distribution, making it appear less normal and potentially impacting the model's predictive performance.

###### 4.1.1.3.2.1.5 Multicollinearity

```{r}
vif_values <- vif(reduced_model)

# Interpret VIF values
# A rule of thumb is that if VIF is greater than 5 or 10, it indicates high multicollinearity.
high_vif <- vif_values[vif_values > 5]
if(length(high_vif) > 0){
  print("The following variables have a high VIF indicating potential multicollinearity:")
  print(high_vif)
} else {
  print("No evidence of concerning multicollinearity among the predictor variables.")
}

vif_values <- c(SearchRatio = 1.08, `Slightly Against`= 23.99, Neutral = 5.46, 
                `In Favour` = 19.36)

# Create a data frame from the VIF values
vif_df <- data.frame(
  Variable = names(vif_values),
  VIF = unname(vif_values),
  Multicollinearity_Interpretation = c(
    "No evidence of concerning multicollinearity among the predictor variables.",
    "Very high, indicating significant multicollinearity.",
    "High, indicating significant multicollinearity.",
    "Very high, indicating significant multicollinearity."
  )
)

# Generate the summary table
vif_table <- kable(vif_df, "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F) %>%
  column_spec(1, bold = TRUE, width = "15em") %>%
  column_spec(2, width = "5em") %>%
  column_spec(3, width = "30em")

# Print the table to view it in R Markdown or R HTML output
vif_table

```

The table indicates that `Slightly Against` and `In Favour` have very high Variance Inflation Factors (VIFs) of 23.99 and 19.32 respectively, pointing to significant multicollinearity issues, which means they share a lot of information and could be problematic for the regression analysis. `Neutral` has a moderate to high VIF, which might also be a concern. `SearchRatio` has a low VIF, suggesting it doesn't have multicollinearity problems with other variables.

##### 4.1.1.3.2.2 Conclusion

Based on the regression results and the graphs, it seems that the final model with variables `SearchRatio`, `Slightly Against`, `Neutral`, and `In Favour` explains a substantial part of the variance in the dependent variable (Multiple R-squared: 0.699). The residuals show some potential outliers, but the histogram suggests most errors are small. While the model appears statistically significant and explains much of the variability, caution should be exercised due to potential outliers and the patterns observed in the residuals, which could indicate model misspecification or the need for transformation of variables.

Significant multicollinearity in the model, especially with `slightly Against` and `In Favour`, casts doubt on the reliability of the regression results and suggests the need for model adjustments or alternative analysis methods.

When considering whether to exclude outliers from our analysis, we
should proceed with caution. Outliers shouldn't be discarded just
because they deviate from the norm; doing so might make our model too
specific to the data we've used, and it might not perform well with new
data. It's important to understand why these data points are outliers:

-   If they're caused by mistakes in data entry or measurement errors,
    it's appropriate to either fix or remove them.
-   If they represent a part of the population that our model doesn't
    adequately explain, this could indicate the need for a more
    sophisticated model.
-   If these outliers are genuine extreme values that naturally occur
    within the dataset, it's essential to keep them. Removing valid data
    points can skew the results.

Given these considerations, we've decided to retain these outliers in
our dataset. By keeping them, we ensure that our analysis accounts for
the full spectrum of data, including those extreme but valid variations,
thereby aiming for a more comprehensive and accurate model.

## 4.2 RQ2 - Are there differences in adoption rate within the different regions in Switzerland? And are there different buying behaviors displayed by the demographic segments within Switzerland?

### EV Adoption per Capita

From the initial data:

In 2005, the EV adoption rate per capita was approximately 0.000004,
which means there were about 4 EVs per million people. By 2009, this
rate increased to approximately 18 EVs per million people.

This approach will give us a general sense of EV adoption in relation to
the overall population but won't provide regional demographic
granularity.

The merged data now includes the total population for each year in
Switzerland and the total count of electric vehicles (EVs) for those
years. We have also calculated the EV adoption rate per capita, which
gives us an insight into how EV adoption scales with the population
size.

These figures show a growing trend in EV adoption in relation to the
population size, albeit the numbers are still quite small relative to
the total population.

The trend shows a gradual increase in EV adoption relative to the
population size, indicating a growing acceptance and usage of electric
vehicles in Switzerland during this period.

```{r}
df_demo <- df_demographic
df_ev <- df_v_electric
# Convert Date and Year to Date type
df_ev$Date <- as.Date(df_ev$Date)
df_demo$Year <- as.Date(df_demo$Year)

# Summing up the population for each year
df_demo$total_population <- rowSums(df_demo[,c("Generation Z", "Millennials", "Generation X", "Baby Boomers")])

# Aggregating EV data by year
df_ev_yearly <- df_ev %>%
  group_by(Year = as.Date(format(Date, "%Y-01-01"))) %>%
  summarize(total_ev = sum(Count))

# Merging the datasets
merged_data <- merge(df_ev_yearly, df_demo, by = "Year")

# Calculating EV adoption per capita
merged_data$ev_per_capita <- merged_data$total_ev / merged_data$total_population

# Creating a ggplot object with your data
p <- ggplot(merged_data, aes(x = Year, y = ev_per_capita, group = 1)) +
  geom_line(color = "darkblue", size = 1) +
  labs(title = "EV Adoption Per Capita Over Time in Switzerland",
       x = "Year",
       y = "EV Adoption Per Capita")

# Animate the plot with gganimate, revealing the line over time
animated_plot <- p +
  transition_reveal(Year)
# Render the animation
animate(animated_plot, renderer = gganimate::gifski_renderer(), width = 600, height = 400, res = 96)
```

### Correlation of EV registration with age groups

The correlation matrix below shows the relationships between the
proportions of different generational groups (Generation Z, Millennials,
Generation X, Baby Boomers) and the EV adoption rate per capita in
Switzerland. The heatmap provides the following insights:

The correlation coefficients indicate the strength and direction of the
relationship between each pair of variables. Positive values suggest a
positive correlation (as one increases, so does the other), while
negative values suggest an inverse relationship.

```{r}
# Data Preparation
df_ev$Date <- as.Date(df_ev$Date)
df_demo$Year <- as.Date(df_demo$Year)

# Summing up the population for each year
df_demo$total_population <- rowSums(df_demo[,c("Generation Z", "Millennials", "Generation X", "Baby Boomers")])

# Calculate proportions
df_demo$prop_gen_z <- df_demo$`Generation Z` / df_demo$total_population
df_demo$prop_millennials <- df_demo$Millennials / df_demo$total_population
df_demo$prop_gen_x <- df_demo$`Generation X` / df_demo$total_population
df_demo$prop_boomers <- df_demo$`Baby Boomers` / df_demo$total_population

# Aggregating EV data by year
df_ev_yearly <- df_ev %>%
  group_by(Year = as.Date(format(Date, "%Y-01-01"))) %>%
  summarize(total_ev = sum(Count))

# Merging the datasets
merged_data <- merge(df_ev_yearly, df_demo, by = "Year")

# Calculating EV adoption per capita
merged_data$ev_per_capita <- merged_data$total_ev / merged_data$total_population

# Correlation Matrix
correlation_matrix <- cor(merged_data[,c("prop_gen_z", "prop_millennials", "prop_gen_x", "prop_boomers", "ev_per_capita")])

# Melting the correlation matrix for ggplot
melted_correlation_matrix <- melt(correlation_matrix)

# Modify the variable names by removing 'prop_' and replacing '_' with ' '
melted_correlation_matrix$Var1 <- gsub("prop_", "", melted_correlation_matrix$Var1)
melted_correlation_matrix$Var2 <- gsub("prop_", "", melted_correlation_matrix$Var2)
melted_correlation_matrix$Var1 <- gsub("_", " ", melted_correlation_matrix$Var1)
melted_correlation_matrix$Var2 <- gsub("_", " ", melted_correlation_matrix$Var2)

# Creating the heatmap
p <- ggplot(melted_correlation_matrix, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(label = sprintf("%.2f", value)), color = "white", size = 4) +
  scale_fill_gradient(low = "lightgreen", high = "darkgreen", name = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "", y = "", title = "Correlation Heatmap")

# Convert to interactive plot
ggplotly(p, tooltip = c("label", "fill"), width = 600, height = 500)
```

### Rural vs Urban

We merged two datasets, one listing Swiss cantons as urban or rural
('df_cantons') and the other tracking monthly electric vehicle counts
('df_ev'), filtered out non-canton data, grouped by urban/rural typology
and month, then calculated a 12-month rolling average to smooth out
variances, and finally created an interactive time-series graph using
'dygraphs' to visually compare EV trends between urban and rural areas
in Switzerland.

Source -
[bfs.admin.ch](https://www.bfs.admin.ch/bfs/en/home/statistics/cross-sectional-topics/city-statistics/urban-switzerland.html)

```{r}
# Text input
text <- "Canton\tUrban-Rural Typology
Aargau\tUrban
Appenzell Ausserrhoden\tRural
Appenzell Innerrhoden\tRural
Basel-Landschaft\tUrban
Basel-Stadt\tUrban
Bern\tUrban
Freiburg\tUrban
Genève\tUrban
Glarus\tRural
Graubünden\tRural
Jura\tRural
Luzern\tUrban
Neuchâtel\tUrban
Nidwalden\tRural
Obwalden\tRural
St. Gallen\tUrban
Schaffhausen\tUrban
Schwyz\tRural
Solothurn\tUrban
Thurgau\tUrban
Ticino\tUrban
Uri\tRural
Valais\tRural
Vaud\tUrban
Zug\tUrban
Zürich\tUrban"

# Split the text into lines
lines <- strsplit(text, "\n")[[1]]

# Split each line into Canton and Typology
data <- strsplit(lines, "\t")

# Extract Cantons and Typologies into separate vectors
cantons <- sapply(data, function(x) x[1])
typologies <- sapply(data, function(x) x[2])

# Remove the header
cantons <- cantons[-1]
typologies <- typologies[-1]

# Create a data frame
dataset <- data.frame(Canton = cantons, Typology = typologies)

# Update the 'Canton' column with abbreviations
df_cantons <- dataset %>%
  mutate(Canton = case_when(
    Canton == "Zürich" ~ "ZH",
    Canton == "Bern" ~ "BE",
    Canton == "Luzerne" ~ "LU",
    Canton == "Uri" ~ "UR",
    Canton == "Schwyz" ~ "SZ",
    Canton == "Obwalden" ~ "OW",
    Canton == "Nidwalden" ~ "NW",
    Canton == "Glarus" ~ "GL",
    Canton == "Zug" ~ "ZG",
    Canton == "Freibourg" ~ "FR",
    Canton == "Solothurn" ~ "SO",
    Canton == "Basel-Stadt" ~ "BS",
    Canton == "Basel-Landschaft" ~ "BL",
    Canton == "Schaffhausen" ~ "SH",
    Canton == "Appenzell Ausserrhoden" ~ "AR", # Adjusted to match your data
    Canton == "Appenzell Innerrhoden" ~ "AI",  # Adjusted to match your data
    Canton == "St. Gallen" ~ "SG",
    Canton == "Graubünden" ~ "GR",
    Canton == "Aargau" ~ "AG",
    Canton == "Thurgau" ~ "TG",
    Canton == "Ticino" ~ "TI",
    Canton == "Vaud" ~ "VD",
    Canton == "Valais" ~ "VS",
    Canton == "Neuchâtel" ~ "NE",
    Canton == "Genève" ~ "GE", # Adjusted to match your data
    Canton == "Jura" ~ "JU",
    TRUE ~ Canton # Default case to keep original names for unmatched entries
  ))

library(xts)
# Filter out 'Confederation' and 'Switzerland' from df_ev before merging
df_ev_filtered <- df_ev %>%
  filter(!Location %in% c("Confederation", "Switzerland"))

# Convert Date to Date format in df_ev_filtered
df_ev_filtered$Date <- as.Date(df_ev_filtered$Date)

# Perform the merge
df_merged <- inner_join(df_ev_filtered, df_cantons, by = c("Location" = "Canton"))

# Create a sequence of all months present in the data
all_months <- seq(from = min(df_merged$Date), to = max(df_merged$Date), by = "1 month")

# Group by Typology and Date (monthly)
df_grouped <- df_merged %>%
  group_by(Typology, Month = floor_date(Date, "month")) %>%
  summarise(Total_EV_Count = sum(Count), .groups = 'drop')

# Make sure that we have all months for each Typology
df_complete <- df_grouped %>%
  complete(Month = all_months, Typology, fill = list(Total_EV_Count = 0))

# Spread the data into separate columns for each Typology
df_wide <- df_complete %>%
  pivot_wider(names_from = Typology, values_from = Total_EV_Count)

# Replace NA with 0 if there are any left after pivot_wider
df_wide[is.na(df_wide)] <- 0

# Convert to xts object for dygraphs
xts_data <- xts(df_wide[, -1], order.by = df_wide$Month)

# Calculate rolling mean
roll_mean <- rollapply(xts_data, width = 12, FUN = mean, by.column = TRUE, align = "right", fill = NA)

# Create the dygraph with options for improved readability
dygraph(roll_mean, main = "Urban vs Rural EV Adoption (12-Month Rolling Mean)", width = "600px", height = "400px") %>%
  dySeries("Urban", label = "Urban", color = "#1c61b6", fillGraph = TRUE) %>%
  dySeries("Rural", label = "Rural", color = "#4daf4a", fillGraph = TRUE) %>%
  dyOptions(strokeWidth = 1.5) %>%
  dyLegend(show = "always") %>%
  dyRangeSelector(height = 20) # Adds a range selector for zooming 
```

The graph displays a clear upward trend in electric vehicle adoption
over time in both urban and rural areas of Switzerland, with urban areas
consistently showing higher counts. This could be due to factors such as
better charging infrastructure, higher population density, or more
environmental awareness in urban regions.

## 4.3 RQ3 - How has the growth of electric vehicles evolved in comparison to other countries such as France, and what factors might account for the differences in their evolution ?

As a matter of fact, the EDA section [(3.7)](#3-7-swiss-vs-france)
already helps us answering this question involving quite strong
arguments. Nevertheless, we decided to find out more about those
differences in evolution by comparing the increase in charging station
spots both in France and Switzerland. To do so, we computed a bar chart
in order to improve the visualisation of this juxtaposition.

```{r}
data <- charge_ch_fr 

# Convert year to Date format and then extract the year
data$year <- as.Date(paste0(data$year, "-01-01"))
data$year <- format(data$year, "%Y")

# Sum the values by year and region
data_summarized <- data %>%
  group_by(year, region) %>%
  summarize(total_value = sum(value))

# Create the ggplot
p <- ggplot(data_summarized, aes(x = year, y = total_value, fill = region)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("France" = "#4E79A7", "Switzerland" = "#F28E2B")) +  # Adjusted custom colors
  labs(title = "Total Availability of Charging Stations in France vs Switzerland",
       x = "Year",
       y = "Total Charging Stations") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5), # Center the plot title
        legend.title = element_blank()) # Remove the legend title

# Convert to interactive plot using plotly
p_interactive <- ggplotly(p)
p_interactive <- ggplotly(p, width = 600, height = 600, tooltip = c("x", "y", "color"))
p_interactive <- p_interactive %>%
  layout(legend = list(orientation = "h", x = 0, xanchor = "left", y = -0.2))
p_interactive
```

The results show that since 2015, France has exponentially increased its
number of stations while Switzerland seems to be gradually adapting. It
is important to take the respective surface and demography differences
of the two countries in consideration.Even with that in mind,
Switzerland seems to be late in terms of adoption of charging station
spots in the last decade. Overall, an increasing number of charging
stations in both countries rhymes with an overall EV adoption for the
two historical friends.

## 4.4 RQ4 - To what extent does the evolution in the availability of charging stations exert an influence on the adoption of electric vehicles in Switzerland?

To evaluate this question in the best conditions, we decided to compute
some empirical plots.

```{r}
# First, let's merge the df_v and df_charge_number_CH data sets, and we will look at Fuel: Electricity

df_v_electric_total_ch <- df_v %>%
  filter(Fuel == "Electricity", VehicleType == "Passenger car", Location == c("Switzerland","Confederation")) %>%
  select(Date, Count)

sum_by_year <- df_v_electric_total_ch %>%
  group_by(Year = lubridate::year(Date)) %>%
  summarise(Total_Count = sum(Count))


# Convert year to a common format for merging
sum_by_year <- sum_by_year %>%
  mutate(year = as.Date(paste0(Year, "-01-01")))

# Merge the datasets based on the "year" column
merged_v_charge <- left_join(sum_by_year, df_charge_number_CH, by = c("year" = "year"))

# cleaning merged data set
merged_v_charge <- merged_v_charge %>%
  filter(Year > "2011") %>%
  select(Year, Total_Count, powertrain, value)

names(merged_v_charge)[names(merged_v_charge) == "Total_count"] <- "EVs"
colnames(merged_v_charge)[colnames(merged_v_charge) == "value"] <- "Charging station"

# Summing Powertrain together
merged_v_charge <- merged_v_charge %>%
  group_by(Year, Total_Count) %>%
  summarise(Count = sum(`Charging station`))

# Checking the correlation
corr_charge_ev <- cor(merged_v_charge$Total_Count, merged_v_charge$Count)

# their correlation is 0.957, almost perfectly correlated (no suprise here)

# Checking for lagged correlation

lags_to_explore <- 1:3

lagged_correlation <- function(data, lag) {
  data %>%
    mutate(Count_Lagged = lag(Count, n = lag, default = NA)) %>%
    summarise(Correlation = cor(Total_Count, Count_Lagged, use = "complete.obs"))
}

# Calculate lagged correlations for each lag
lagged_correlations_df <- data.frame(Lag = lags_to_explore) %>%
  rowwise() %>%
  mutate(Correlation = lagged_correlation(merged_v_charge[, -1], Lag)$Correlation)

# Print the results
print("Original Correlation:")
print(corr_charge_ev)

print("Lagged Correlations:")
print(lagged_correlations_df)


# Now we formulate the following Hypothesis

# H0: new charging station increase EV adoption vs. H1: new charging station does not increase EV adoption

# Check these hypotheses with a simple linear regression
linear_charging <- lm(Total_Count ~ Count, data = merged_v_charge)

# Poisson Test
poisson_model <- glm(Total_Count ~ Count, family = poisson, data = merged_v_charge)

# Set up the layout using mfrow
par(mfrow = c(1, 2))  # 1 row, 2 columns

# Plotting for Simple Linear Regression
plot(linear_charging, 1, main = "LM Residuals vs Fitted")
plot(linear_charging, 2, main = "LM Normal Q-Q Plot")
plot(linear_charging, 3, main = "LM Scale-Location Plot")
plot(linear_charging, 5, main = "LM Residuals vs Leverage")

# Plotting for Poisson Regression
plot(poisson_model, which = 1, main = "Poisson Residuals vs Fitted")
plot(poisson_model, which = 2, main = "Poisson Normal Q-Q Plot")
plot(poisson_model, which = 3, main = "Poisson Scale-Location Plot")
plot(poisson_model, which = 5, main = "Poisson Residuals vs Leverage")

# Printing
summary(linear_charging)
summary(poisson_model)
# Reset the layout
par(mfrow = c(1, 1))
```

The year-on-year correlation is the highest, the lagged correlation
diminishes. We could suggest hat the availability of charging stations
and the new registration of EVs go hand-in-hand, and that the
availability of new charging station does not create a demand of new EVs
by itself. Correlation does not imply causation, while we see a
relationship, we can't conclude that charging stations directly cause
changes in electric vehicle adoption only with a Correlation analysis

For this research question, we used both a linear regression and a
Poisson-test. It is important to note that the Poisson test presents
major limitations in our case, as it assumes constant rates (we have
seen that both the adoption of EVs and charging station availability
present exponential nature). However, we decided to still include it in
our report.

With both a linear regression and a Poisson-test. We find evidence of
statistically significant relationship between the count of available
charging station and the count of electric vehicles registered. We have
Prediction variable/coefficient of 2.68 x 10\^-4 and 3.34 respectively.
And a p-val \< 0.005 for both. However, it is important to remind
ourselves that these variables have a bidirectional / mutual influence,
beyond the scope of what our analysis shows. The relationship is not
strictly unidirectional and therefore, it is hard to conclude anything
without further domain-knowledge and context-specific information
